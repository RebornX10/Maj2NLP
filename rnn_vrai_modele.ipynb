{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O7tzMnWr3yfe"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import pad_sequences\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.models import Model\n",
        "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PAboikDhW1mt",
        "outputId": "65875962-c07a-4819-bf2b-ce07c77e9138"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G_D16E0eegUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4TVmKeC-3yfi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1af64de8-383e-4a5d-d674-3a5ed8f5698c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py:3326: DtypeWarning: Columns (3) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        }
      ],
      "source": [
        "dossier='/content/drive/MyDrive/'\n",
        "df=pd.read_csv(dossier+'text_preprocessed_boubacar.csv')\n",
        "df=df.astype(str).sample(df.shape[0]//150)\n",
        "df_questions=df[\"Title\"]\n",
        "df_answers=df[\"Answers\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u6Lft84-TPfC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJbKL3xI3yfj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "2430027d-91f2-4a7d-b073-0ccc8f200dd1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Unnamed: 0                                              Title  \\\n",
              "123181     123181                       python - display image web ?   \n",
              "120962     120962          python screenshot 2+ monitors ( windows )   \n",
              "211809     211809  python-sympy : lambdify returns wrong answer f...   \n",
              "12658       12658                     python error using urllib.open   \n",
              "262748     262748  programatically exiting python script multithr...   \n",
              "\n",
              "                                                  Content  \\\n",
              "123181  using python make `` web album viewer '' , mee...   \n",
              "120962  make screenshot python , connected multiple mo...   \n",
              "211809  baffled answer following code 10 1. someone he...   \n",
              "12658   run : import urllib feed = urllib.urlopen ( ``...   \n",
              "262748  code runs routinely , every ( like month ) pro...   \n",
              "\n",
              "                                                  Answers  \n",
              "123181  list contains decimal numbers , however exampl...  \n",
              "120962  client sends string `` abcd '' half closes soc...  \n",
              "211809  xml document . want pull text .. < .p > tags ....  \n",
              "12658   large infrastructure written python 2.6 , rece...  \n",
              "262748  stumbled upon pure python implementation calcu...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b78c3dfc-0850-4dbd-8327-aa6ad144ff69\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Title</th>\n",
              "      <th>Content</th>\n",
              "      <th>Answers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>123181</th>\n",
              "      <td>123181</td>\n",
              "      <td>python - display image web ?</td>\n",
              "      <td>using python make `` web album viewer '' , mee...</td>\n",
              "      <td>list contains decimal numbers , however exampl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120962</th>\n",
              "      <td>120962</td>\n",
              "      <td>python screenshot 2+ monitors ( windows )</td>\n",
              "      <td>make screenshot python , connected multiple mo...</td>\n",
              "      <td>client sends string `` abcd '' half closes soc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>211809</th>\n",
              "      <td>211809</td>\n",
              "      <td>python-sympy : lambdify returns wrong answer f...</td>\n",
              "      <td>baffled answer following code 10 1. someone he...</td>\n",
              "      <td>xml document . want pull text .. &lt; .p &gt; tags ....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12658</th>\n",
              "      <td>12658</td>\n",
              "      <td>python error using urllib.open</td>\n",
              "      <td>run : import urllib feed = urllib.urlopen ( ``...</td>\n",
              "      <td>large infrastructure written python 2.6 , rece...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>262748</th>\n",
              "      <td>262748</td>\n",
              "      <td>programatically exiting python script multithr...</td>\n",
              "      <td>code runs routinely , every ( like month ) pro...</td>\n",
              "      <td>stumbled upon pure python implementation calcu...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b78c3dfc-0850-4dbd-8327-aa6ad144ff69')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b78c3dfc-0850-4dbd-8327-aa6ad144ff69 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b78c3dfc-0850-4dbd-8327-aa6ad144ff69');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z4NWjWTK99W8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nBaohEX93yfk"
      },
      "outputs": [],
      "source": [
        "questions_train, questions_test, answers_train, answers_test = train_test_split(df_questions,df_answers, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rgDrwCysEg5s"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import pad_sequences\n",
        "from keras.layers import Embedding, LSTM, Dense\n",
        "from keras.models import Sequential\n",
        "\n",
        "# Créer un tokenizer pour convertir les phrases en séquences de mots\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
        "tokenizer.fit_on_texts(questions_train)\n",
        "\n",
        "# Convertir les phrases en séquences de mots\n",
        "questions_train = tokenizer.texts_to_sequences(questions_train)\n",
        "questions_test = tokenizer.texts_to_sequences(questions_test)\n",
        "\n",
        "\n",
        "# Créer un tokenizer pour convertir les phrases en séquences de mots\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
        "tokenizer.fit_on_texts(answers_train)\n",
        "\n",
        "# Convertir les phrases en séquences de mots\n",
        "answers_train = tokenizer.texts_to_sequences(answers_train)\n",
        "answers_test = tokenizer.texts_to_sequences(answers_test)\n",
        "\n",
        "max_length_questions = max([len(s) for s in questions_train])\n",
        "max_length_answers = max([len(s) for s in answers_train])\n",
        "max_length=max([max_length_questions, max_length_answers])\n",
        "# Pad les séquences pour qu'elles aient toutes la même longueur\n",
        "\n",
        "questions_train = tf.keras.preprocessing.sequence.pad_sequences(questions_train, maxlen=max_length)\n",
        "questions_test = tf.keras.preprocessing.sequence.pad_sequences(questions_test, maxlen=max_length)\n",
        "\n",
        "\n",
        "# Pad les séquences pour qu'elles aient toutes la même longueur\n",
        "\n",
        "answers_train = tf.keras.preprocessing.sequence.pad_sequences(answers_train, maxlen=max_length)\n",
        "answers_test = tf.keras.preprocessing.sequence.pad_sequences(answers_test, maxlen=max_length)\n",
        "\n",
        "# Créer un encoder-decoder avec un LSTM\n",
        "encoder_inputs = Input(shape=(max_length,1))\n",
        "encoder = Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=64, input_length=max_length_questions)(encoder_inputs)\n",
        "encoder = LSTM(64, return_state=True, return_sequences=True)\n",
        "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "decoder_inputs = Input(shape=(max_length,))\n",
        "decoder_embedding = Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=64, input_length=max_length)(decoder_inputs)\n",
        "decoder_lstm = LSTM(64, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
        "decoder_dense = Dense(len(tokenizer.word_index)+1, activation='softmax')\n",
        "outputs = decoder_dense(decoder_outputs)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iUBnLftDFvsW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "BeWV8pR65Gju"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5m_8hFUT3yfl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61c8e432-5761-4a05-9b39-486506e2cce0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "2/2 [==============================] - 35s 21s/step - loss: 9.7833 - accuracy: 0.0000e+00 - val_loss: 9.7755 - val_accuracy: 0.9566\n",
            "Epoch 2/10\n",
            "2/2 [==============================] - 26s 18s/step - loss: 9.7728 - accuracy: 0.9316 - val_loss: 9.7622 - val_accuracy: 0.9591\n",
            "Epoch 3/10\n",
            "2/2 [==============================] - 31s 18s/step - loss: 9.7577 - accuracy: 0.9630 - val_loss: 9.7420 - val_accuracy: 0.9609\n",
            "Epoch 4/10\n",
            "2/2 [==============================] - 26s 18s/step - loss: 9.7341 - accuracy: 0.9667 - val_loss: 9.7067 - val_accuracy: 0.9621\n",
            "Epoch 5/10\n",
            "2/2 [==============================] - 27s 19s/step - loss: 9.6911 - accuracy: 0.9734 - val_loss: 9.6361 - val_accuracy: 0.9631\n",
            "Epoch 6/10\n",
            "2/2 [==============================] - 26s 18s/step - loss: 9.6049 - accuracy: 0.9629 - val_loss: 9.4881 - val_accuracy: 0.9635\n",
            "Epoch 7/10\n",
            "2/2 [==============================] - 26s 18s/step - loss: 9.4311 - accuracy: 0.9701 - val_loss: 9.2599 - val_accuracy: 0.9637\n",
            "Epoch 8/10\n",
            "2/2 [==============================] - 26s 18s/step - loss: 9.2008 - accuracy: 0.9546 - val_loss: 9.0064 - val_accuracy: 0.9637\n",
            "Epoch 9/10\n",
            "2/2 [==============================] - 28s 19s/step - loss: 8.9461 - accuracy: 0.9586 - val_loss: 8.7506 - val_accuracy: 0.9637\n",
            "Epoch 10/10\n",
            "2/2 [==============================] - 26s 18s/step - loss: 8.6822 - accuracy: 0.9694 - val_loss: 8.4949 - val_accuracy: 0.9637\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7d960b9820>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "\n",
        "# Compiler le modèle\n",
        "model = Model([encoder_inputs, decoder_inputs], [outputs])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "# Entraîner le modèle\n",
        "model.fit([questions_train, questions_train], answers_train, epochs=10, batch_size=8, validation_data=([questions_test, answers_test], answers_test), steps_per_epoch=2, validation_steps=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NEn7oQBoMg98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bNhGjEY33yfm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98d4bc35-b994-41d5-e8d1-3efc373da6ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.9659793972969055\n"
          ]
        }
      ],
      "source": [
        "# Évaluer le modèle sur les données de test\n",
        "loss, acc = model.evaluate([questions_test, questions_test], answers_test, verbose=0, batch_size=8)\n",
        "print(\"Test accuracy:\", acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fE8DRpcK3yfn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8210fe1-ce44-4b24-b977-4f83e3a290bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import preprocessing,metrics,manifold\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.model_selection import train_test_split,cross_val_score,GridSearchCV,cross_val_predict\n",
        "from imblearn.over_sampling import ADASYN,SMOTE\n",
        "from imblearn.under_sampling import NearMiss\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.svm import SVC\n",
        "import collections\n",
        "import matplotlib.patches as mpatches\n",
        "from sklearn.metrics import accuracy_score\n",
        "%matplotlib inline\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "import xgboost\n",
        "from imblearn.metrics import classification_report_imbalanced\n",
        "from sklearn.metrics import classification_report,roc_auc_score,roc_curve,r2_score,recall_score,confusion_matrix,precision_recall_curve\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import StratifiedKFold,KFold,StratifiedShuffleSplit\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words('english')\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA, TruncatedSVD,SparsePCA\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "from nltk.tokenize import word_tokenize\n",
        "from collections import defaultdict\n",
        "from collections import Counter\n",
        "import seaborn as sns\n",
        "from wordcloud import WordCloud,STOPWORDS\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "from plotly import tools\n",
        "import plotly.offline as py\n",
        "py.init_notebook_mode(connected=True)\n",
        "import plotly.graph_objs as go"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "pvkIACmZiga2",
        "outputId": "06fd905d-5a8c-4118-e0f5-9ec5826fe7de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-2.8.3.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import *\n",
        "def stem_traincorpus(data):\n",
        "    stemmer = PorterStemmer()\n",
        "    out_data=\"\"\n",
        "    for words in data:\n",
        "        out_data+= stemmer.stem(words)\n",
        "    return out_data\n",
        "def remove_stopwords(data):\n",
        "  text=data.lower()\n",
        "  text_tokens = word_tokenize(text)\n",
        "  tokens_without_sw = [word for word in text_tokens if not word in stop_words]\n",
        "  return (\" \").join(tokens_without_sw)"
      ],
      "metadata": {
        "id": "pCoO7DooiANp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wLozOaqIiBOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JcTn7YjX3yfo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624
        },
        "outputId": "e24dd3d0-3294-4a9e-bc05-59b21e43faf9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 342ms/step\n",
            "[[[6.4416396e-05 6.2272818e-05 6.2088984e-05 ... 5.6042227e-05\n",
            "   5.6085068e-05 5.5862856e-05]\n",
            "  [6.8022717e-05 6.4813968e-05 6.4376924e-05 ... 5.6124220e-05\n",
            "   5.6060366e-05 5.5790140e-05]\n",
            "  [7.2230439e-05 6.7727771e-05 6.6965811e-05 ... 5.6209959e-05\n",
            "   5.6037028e-05 5.5711065e-05]\n",
            "  ...\n",
            "  [2.1312956e-04 1.4995305e-04 1.3753820e-04 ... 5.6410256e-05\n",
            "   5.5155899e-05 5.3833661e-05]\n",
            "  [2.1312956e-04 1.4995305e-04 1.3753820e-04 ... 5.6410256e-05\n",
            "   5.5155899e-05 5.3833661e-05]\n",
            "  [2.1312956e-04 1.4995305e-04 1.3753820e-04 ... 5.6410256e-05\n",
            "   5.5155899e-05 5.3833661e-05]]]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-f5a7d2eba6cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mnew_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredict_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"print message screen\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequences_to_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_text\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;31m#tableau=np.array([questions_train, answers_train])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m#tableau.reshape(1,tableau.shape[1],tableau.shape[2])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/preprocessing/text.py\u001b[0m in \u001b[0;36msequences_to_texts\u001b[0;34m(self, sequences)\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtexts\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstrings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m     \"\"\"\n\u001b[0;32m--> 395\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequences_to_texts_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0msequences_to_texts_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/preprocessing/text.py\u001b[0m in \u001b[0;36msequences_to_texts_generator\u001b[0;34m(self, sequences)\u001b[0m\n\u001b[1;32m    415\u001b[0m       \u001b[0mvect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mnum\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m         \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_word\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mnum_words\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnum\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mnum_words\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'numpy.ndarray'"
          ]
        }
      ],
      "source": [
        "import keras\n",
        "#def prediction\n",
        "def predict_text(#define input text and model\n",
        "                 input_text, tokenizer, model, \n",
        "                 #define tokenizer maximum length of sequence\n",
        "                 maxlen_seq, padding = 'post', truncating = 'post'\n",
        "                 ):\n",
        "    \n",
        "    #prediction\n",
        "    text = str(input_text)\n",
        "    sequence = tokenizer.texts_to_sequences([text])\n",
        "    sequence = pad_sequences(sequence, maxlen = maxlen_seq)\n",
        "    predict = model.predict([sequence,sequence])\n",
        "    \n",
        "    return predict\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
        "new_text=predict_text(\"print message screen\",tokenizer,model,max_length)\n",
        "print(new_text)\n",
        "a=tokenizer.sequences_to_texts([new_text])\n",
        "#tableau=np.array([questions_train, answers_train])\n",
        "#tableau.reshape(1,tableau.shape[1],tableau.shape[2])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "chatbot",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.15"
    },
    "vscode": {
      "interpreter": {
        "hash": "03041b0ab7cd1638a53e9defcca4554f53cc9626e5c5fef97f44058438290e8d"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}