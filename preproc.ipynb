{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Preprocessing for the questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time as time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.tokenize import ToktokTokenizer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tag.util import untag\n",
    "import contractions\n",
    "# import pycontractions # Alternative better package for removing contractions\n",
    "from autocorrect import Speller\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtypes_questions = {'Id':'int32', 'Score': 'int16', 'Title': 'str', 'Body': 'str'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(607282, 4)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_questions = pd.read_csv('../Maj2NLP/data/Questions.csv', usecols=['Id', 'Score', 'Title', 'Body'], dtype=dtypes_questions, encoding_errors= 'replace')\n",
    "df_questions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_questions[['Title', 'Body']] = df_questions[['Title', 'Body']]\\\n",
    "    .applymap(lambda x: str(x)\\\n",
    "              .encode(\"utf-8\", errors='surrogatepass')\\\n",
    "              .decode(\"ISO-8859-1\", errors='surrogatepass'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove all the questions with a negative score\n",
    "df_questions = df_questions[df_questions['Score'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spell = Speller()\n",
    "token = ToktokTokenizer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "charac = '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~0123456789'\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "adjective_tag_list = set(['JJ','JJR', 'JJS', 'RBR', 'RBS']) # List of Adjective's tag from nltk package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 327688 entries, 0 to 607280\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   Id      327688 non-null  int32 \n",
      " 1   Score   327688 non-null  int16 \n",
      " 2   Title   327688 non-null  object\n",
      " 3   Body    327688 non-null  object\n",
      "dtypes: int16(1), int32(1), object(2)\n",
      "memory usage: 9.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_questions.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Now let's remove HTML tags from the questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samuel.adone@cdbdx.biz/Documents/Ynov/M1/NLP/Maj2NLP/venv/lib/python3.9/site-packages/bs4/__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Parse question and title then return only the text\n",
    "df_questions['Body'] = df_questions['Body'].apply(lambda x: BeautifulSoup(x, 'html.parser').get_text())\n",
    "df_questions['Title'] = df_questions['Title'].apply(lambda x: BeautifulSoup(x, 'html.parser').get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Ruby can add methods to the Number class and other core types to get effects like:\\n\\n1.should_equal(1)\\n\\nBut it seems like python cannot do this. Is this true? And if so, why? Does it have something to do with the fact that type can't be modified?\\nUpdate: Rather than talking about different definitions of monkey patching, I would like to just focus on the example above. I have already concluded that it cannot be done as a few of you have answered. But I would like a more detailed explanation of why it cannot be done, and maybe what feature, if available in python, would allow this.\\nTo answer some of you: The reason I might want to do this is simply aesthetics/readability. \\n\\nitem.price.should_equal(19.99)\\n\\nreads more like English and clearly indicates which is the tested value and which is the expected value, as supposed to:\\n\\nshould_equal(item.price, 19.99)\\n\\nThis concept is what Rspec and some other Ruby frameworks are based on.\\n\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_questions['Body'][768]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### every other things to removes such as \\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r\"\\'\", \"'\", text) # apostrophe characters to whitespace\n",
    "    text = re.sub(r\"\\n\", \" \", text) # newlines to whitespace\n",
    "    text = re.sub(r\"\\xa0\", \" \", text) # non-breakable to whitespace\n",
    "    text = re.sub('\\s+', ' ', text) # more than one whitespace character to a single whitespace\n",
    "    text = text.strip(' ')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_questions['Title'] = df_questions['Title'].apply(lambda x: clean_text(x))\n",
    "df_questions['Body'] = df_questions['Body'].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I\\'m creating an ZIP file with ZipFile in Python 2.5, it works ok so far: import zipfile, os locfile = \"test.txt\" loczip = os.path.splitext (locfile)[0] + \".zip\" zip = zipfile.ZipFile (loczip, \"w\") zip.write (locfile) zip.close() but I couldn\\'t find how to encrypt the files in the ZIP file. I could use system and call PKZIP -s, but I suppose there must be a more \"Pythonic\" way. I\\'m looking for an open source solution.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_questions['Body'][43]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# expand_contractions (i.e \"wasn't\", don't', isn't, 'i've')\n",
    "def expand_contractions(text):\n",
    "    text = contractions.fix(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_questions['Title'] = df_questions['Title'].apply(lambda x: expand_contractions(x))\n",
    "df_questions['Body'] = df_questions['Body'].apply(lambda x: expand_contractions(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the best way to sanitise user input for a Python-based web application? Is there a single function to remove HTML characters and any other necessary characters combinations to prevent an XSS or SQL injection attack?'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_questions['Body'][42]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Spelling Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def autocorrect(text):\n",
    "    words = token.tokenize(text)\n",
    "    words_correct = [spell(w) for w in words]\n",
    "    return ' '.join(map(str, words_correct)) # Return the text untokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df_questions['Title'] = df_questions['Title'].apply(lambda x: autocorrect(x))\n",
    "#df_questions['Body'] = df_questions['Body'].apply(lambda x: autocorrect(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "\"I am using the Photoshop's javascript API to find the fonts in a given PSD. Given a font name returned by the API, I want to find the actual physical font file that that font name corresponds to on the disc. This is all happening in a python program running on OSX so I guess I am looking for one of: Some Photoshop javascript A Python function An OSX API that I can call from python\""
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_questions['Body'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_questions.to_csv('../Maj2NLP/data/questions_preprocessed.csv', encoding='utf-8', errors='surrogatepass')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Lowering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_questions['Title'] = df_questions['Title'].str.lower()\n",
    "df_questions['Body'] = df_questions['Body'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "\"i am using the photoshop's javascript api to find the fonts in a given psd. given a font name returned by the api, i want to find the actual physical font file that that font name corresponds to on the disc. this is all happening in a python program running on osx so i guess i am looking for one of: some photoshop javascript a python function an osx api that i can call from python\""
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_questions['Body'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### remove all non alphabetical characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def remove_punctuation_and_number(text):\n",
    "    \"\"\"remove all punctuation and number\"\"\"\n",
    "    return text.translate(str.maketrans(\" \", \" \", charac))\n",
    "\n",
    "\n",
    "\n",
    "def remove_non_alphabetical_character(text):\n",
    "    \"\"\"remove all non-alphabetical character\"\"\"\n",
    "    text = re.sub(\"[^a-z]+\", \" \", text) # remove all non-alphabetical character\n",
    "    text = re.sub(\"\\s+\", \" \", text) # remove whitespaces left after the last operation\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_questions['Title'] = df_questions['Title'].apply(lambda x: remove_non_alphabetical_character(x))\n",
    "df_questions['Body'] = df_questions['Body'].apply(lambda x: remove_non_alphabetical_character(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'i am using the photoshop s javascript api to find the fonts in a given psd given a font name returned by the api i want to find the actual physical font file that that font name corresponds to on the disc this is all happening in a python program running on osx so i guess i am looking for one of some photoshop javascript a python function an osx api that i can call from python'"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_questions['Body'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_questions.to_csv('../Maj2NLP/data/questions_preprocessed_long.csv', encoding='utf-8', errors='surrogatepass')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 653168 entries, 0 to 987118\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   Id        653168 non-null  int32 \n",
      " 1   ParentId  653168 non-null  int64 \n",
      " 2   Score     653168 non-null  int16 \n",
      " 3   Body      653168 non-null  object\n",
      "dtypes: int16(1), int32(1), int64(1), object(1)\n",
      "memory usage: 18.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df_answers = pd.read_csv('../Maj2NLP/data/Answers.csv', usecols=['Id', 'Score', 'Body', 'ParentId'],\n",
    "                           dtype=dtypes_questions, encoding_errors= 'replace')\n",
    "df_answers[['Body']] = df_answers[['Body']] \\\n",
    "    .applymap(lambda x: str(x) \\\n",
    "              .encode(\"utf-8\", errors='surrogatepass') \\\n",
    "              .decode(\"ISO-8859-1\", errors='surrogatepass'))\n",
    "# remove all the questions with a negative score\n",
    "df_answers = df_answers[df_answers['Score'] > 0]\n",
    "spell = Speller()\n",
    "token = ToktokTokenizer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "charac = '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~0123456789'\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "adjective_tag_list = set(['JJ', 'JJR', 'JJS', 'RBR', 'RBS'])  # List of Adjective's tag from nltk package\n",
    "df_answers.info()\n",
    "\n",
    "df_answers['Body'] = df_answers['Body'].apply(lambda x: BeautifulSoup(x, 'html.parser').get_text())\n",
    "\n",
    "df_answers['Body'] = df_answers['Body'].apply(lambda x: clean_text(x))\n",
    "\n",
    "df_answers['Body'] = df_answers['Body'].apply(lambda x: expand_contractions(x))\n",
    "\n",
    "#df_answers['Body'] = df_answers['Body'].apply(lambda x: autocorrect(x))\n",
    "## Lowering\n",
    "df_answers['Body'] = df_answers['Body'].str.lower()\n",
    "\n",
    "df_answers['Body'] = df_answers['Body'].apply(lambda x: remove_non_alphabetical_character(x))\n",
    "df_answers.to_csv('../Maj2NLP/data/answers_preprocessed.csv', encoding='utf-8', errors='surrogatepass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "03041b0ab7cd1638a53e9defcca4554f53cc9626e5c5fef97f44058438290e8d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
